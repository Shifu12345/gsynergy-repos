{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3705eb49-42b5-4e00-8c8a-7635f52af7aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table if exists processed_data.dim_str_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22d50b34-fcd5-4f11-bd12-dda25f42d6f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "#---Load data dfs\n",
    "df_inv_loc = spark.sql(\"select * from raw_data.dim_inv_loc\")  # Inventory locations\n",
    "df_pos_site = spark.sql(\"select * from raw_data.dim_pos_site\")  # POS sites\n",
    "df_rtl_loc = spark.sql(\"select * from raw_data.dim_rtl_loc\")  # Retail locations\n",
    "\n",
    "#rewrite the column names\n",
    "df_inv_loc = df_inv_loc.select(\n",
    "    col(\"loc\").alias(\"location_id\"),\n",
    "    col(\"loc_label\").alias(\"location_label\"),\n",
    "    col(\"loctype_label\").alias(\"location_type\"),\n",
    ")\n",
    "df_inv_loc = df_inv_loc.withColumn(\n",
    "    \"location_type\",\n",
    "    when(col(\"location_type\").isin([\"Store\", \"Retail Store\", \"Retail POS\"]), \"Retail Store\")\n",
    "    .otherwise(col(\"location_type\"))\n",
    ")\n",
    "\n",
    "df_pos_site = df_pos_site.select(\n",
    "    col(\"site_id\").alias(\"location_id\"),\n",
    "    col(\"site_label\").alias(\"location_label\"),\n",
    "    col(\"chnl_label\").alias(\"location_type\"),\n",
    "    col(\"subchnl_label\").alias(\"channel\")\n",
    ")\n",
    "df_pos_site = df_pos_site.withColumn(\n",
    "    \"location_type\",\n",
    "    when(col(\"location_type\").isin([\"Store\", \"Retail Store\", \"Retail POS\"]), \"Retail Store\")\n",
    "    .otherwise(col(\"location_type\"))\n",
    ")\n",
    "\n",
    "df_rtl_loc = df_rtl_loc.select(\n",
    "    col(\"str\").alias(\"location_id\"),\n",
    "    col(\"str_label\").alias(\"location_label\"),\n",
    "    lit(\"Retail Store\").alias(\"location_type\"),\n",
    "    col(\"dstr_label\").alias(\"district\"),\n",
    "    col(\"rgn_label\").alias(\"region\")\n",
    ")\n",
    "df_rtl_loc = df_rtl_loc.withColumn(\n",
    "    \"location_type\",\n",
    "    when(col(\"location_type\").isin([\"Store\", \"Retail Store\", \"Retail POS\"]), \"Retail Store\")\n",
    "    .otherwise(col(\"location_type\"))\n",
    ")\n",
    "\n",
    "#Extract only numeric values from location_id\n",
    "df_pos_site = df_pos_site.withColumn(\"location_id\", regexp_extract(col(\"location_id\"), r'^\\d+$', 0))\n",
    "\n",
    "#Filter out empty values (non-numeric values become empty strings)\n",
    "df_pos_site = df_pos_site.filter(col(\"location_id\") != \"\")\n",
    "\n",
    "#----Convert location_id to IntegerType\n",
    "df_pos_site = df_pos_site.withColumn(\"location_id\", col(\"location_id\").cast(IntegerType()))\n",
    "\n",
    "\n",
    "#Combine all locations and remove duplicates\n",
    "df_dim_str_location = df_inv_loc[['location_id','location_label','location_type']].join(df_pos_site[['location_id','channel']],on=\"location_id\",how=\"inner\").join(df_rtl_loc[['location_id','region','district']],on=\"location_id\",how=\"inner\")\n",
    "\n",
    "#unique primary key sarrogate key\n",
    "df_dim_str_location = df_dim_str_location.withColumn(\"dim_location_id\", monotonically_increasing_id())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c18f9b5e-cdd3-4e26-a98e-6510ec4c36fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#------initial loding of table------\n",
    "df_dim_str_location.write.mode(\"overwrite\").saveAsTable(\"processed_data.dim_str_location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86af73e0-f8a0-49a6-9d6c-19c95d0bcd8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Defining the expected Schema of the table dim_str_location\n",
    "expected_schema = {\n",
    "    \"location_id\": \"int\",\n",
    "    \"location_label\": \"string\",\n",
    "    \"location_type\": \"string\",\n",
    "    \"channel\": \"string\",\n",
    "    \"region\": \"string\",\n",
    "    \"district\": \"string\",\n",
    "    \"dim_location_id\": \"bigint\",\n",
    "}\n",
    "\n",
    "#1. Schema Validation - Ensure data types are correct\n",
    "for column, dtype in expected_schema.items():\n",
    "    actual_dtype = df_dim_str_location.schema[column].dataType.simpleString()\n",
    "    if actual_dtype != dtype:\n",
    "        print(f\"Schema Mismatch: Column {column} expected {dtype}, but got {actual_dtype}\")\n",
    "\n",
    "#2. Null Value Check - Ensure No Missing Data in Key Columns\n",
    "null_check_df = df_dim_str_location.select(\n",
    "    [count(when(col(c).isNull(), c)).alias(c) for c in expected_schema.keys()]\n",
    ")\n",
    "null_check_df.show()\n",
    "\n",
    "#3. Duplicate Check\n",
    "duplicate_count = df_dim_str_location.groupBy(\"location_id\").count().filter(col(\"count\") > 1).count()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Warning: Found {duplicate_count} duplicate location_id records\")\n",
    "\n",
    "#4. Invalid Location ID Check - Ensure Only Numeric IDs\n",
    "invalid_location_ids = df_dim_str_location.filter(col(\"location_id\").isNull() | (col(\"location_id\") <= 0))\n",
    "if invalid_location_ids.count() > 0:\n",
    "    print(\"Warning: Found invalid location_id values\")\n",
    "\n",
    "if duplicate_count == 0 and invalid_location_ids.count() == 0:\n",
    "    df_dim_str_location.write.mode(\"overwrite\").saveAsTable(\"processed_data.dim_str_location\")\n",
    "    print(\"Data passed all quality checks and loaded successfully\")\n",
    "else:\n",
    "    print(\"Data quality checks failed,need fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20cb1f3e-8567-4195-92e1-e75f8c8d767e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from processed_data.dim_location"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3507497059829551,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "processed_data str_location table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
